{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Clasificador de gatos y perros con una CNN\n",
    "\n",
    "\n",
    "## Comenzando\n",
    "\n",
    "### Prerequisitos\n",
    "\n",
    "Necesitaremos:\n",
    "* Tensorflow: Librería de machine learning creada poro google, se instala con *pip install tensorflow*\n",
    "* Keras:      Framework que simplifica el uso de tensorflow, se instala con *pip install keras*\n",
    "* pickle:     Nos ayuda a cargar el dataset preprocesado, viene instalado por defecto.\n",
    "* Opencv:     Nos ayuda a mostrar las fotos en la parte final del código.\n",
    "\n",
    "\n",
    "Además de estos paquetes, necesitará la base de datos preprocesada que se facilitará\n",
    "\n",
    "Tambien puede visualizar la base de datos sin procesar en el siguiente link:\n",
    "\n",
    "https://www.microsoft.com/en-us/download/confirmation.aspx?id=54765\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comenzamos importando los paquetes que utilizaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora cargaremos la base de datos preprocesada, X correspondiendo a las imagenes desordenadas e y a sus respectivas etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar los valores genera una mejora considerable en los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora generaremos nuestro modelo\n",
    "\n",
    "La estructura básica de una CNN es: \n",
    "\n",
    "* Convolución -> Agrupación (pooling) -> Convolución -> Agrupación(Pooling) -> Capa completamente conectada -> Salida\n",
    "\n",
    "<img src=\"http://www.mdpi.com/entropy/entropy-19-00242/article_deploy/html/images/entropy-19-00242-g001.png\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero diremos que es secuencial la forma en la que se conectan las capas.\n",
    "model = Sequential()\n",
    "#Ahora podemos ir añadiendo o quitando capas.\n",
    "#Comenzaremos con convolutional layer que será de dos dimensiones ya que es la forma de nuestras imagenes.\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
    "#Ahora añadimos nuestra función de activación\n",
    "model.add(Activation('relu'))\n",
    "# Agrupamos utilizando maxpooling, que simplemente toma el valor máximo de la ventana que analiza .\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#repetimos otra vez\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Ahora con Flatten convertiremos nuestro mapa de caracterizticas 3D a un vector de 1D.\n",
    "model.add(Flatten())\n",
    "#Futuro análisis revela que para este caso en específico no necesitamos Dense layer, mas se mantendrá por metodología.\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#Ahora añadiremos nuestra función de activación, tener un entendimiento de la salida del modelo, nos ayuda a elegir el tipo.\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "#Por ultimo compilaremos nuestro modelo, especificando como se moverá nuestra pérdida, que optimizador utilizaremos y que valor mediremos.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, batch_size=32, epochs=3, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para optimizar el modelo se suele utilizar la regla de moverse +- una capa y comprobar su desempeño, buscando indicios de overfiting \n",
    "\n",
    "##### En este caso veremos las siguientes combinaciones\n",
    "* 1-conv-32-nodes-0-dense-1534801383\n",
    "* 2-conv-32-nodes-0-dense-1534801383\n",
    "* 3-conv-32-nodes-0-dense-1534801383\n",
    "* 1-conv-64-nodes-0-dense-1534801383\n",
    "* 2-conv-64-nodes-0-dense-1534801383\n",
    "* 3-conv-64-nodes-0-dense-1534801383\n",
    "* 1-conv-128-nodes-0-dense-1534801383\n",
    "* 2-conv-128-nodes-0-dense-1534801383\n",
    "* 3-conv-128-nodes-0-dense-1534801383\n",
    "* 1-conv-32-nodes-1-dense-1534801383\n",
    "* 2-conv-32-nodes-1-dense-1534801383\n",
    "* 3-conv-32-nodes-1-dense-1534801383\n",
    "* 1-conv-64-nodes-1-dense-1534801383\n",
    "* 2-conv-64-nodes-1-dense-1534801383\n",
    "* 3-conv-64-nodes-1-dense-1534801383\n",
    "* 1-conv-128-nodes-1-dense-1534801383\n",
    "* 2-conv-128-nodes-1-dense-1534801383\n",
    "* 3-conv-128-nodes-1-dense-1534801383\n",
    "* 1-conv-32-nodes-2-dense-1534801383\n",
    "* 2-conv-32-nodes-2-dense-1534801383\n",
    "* 3-conv-32-nodes-2-dense-1534801383\n",
    "* 1-conv-64-nodes-2-dense-1534801383\n",
    "* 2-conv-64-nodes-2-dense-1534801383\n",
    "* 3-conv-64-nodes-2-dense-1534801383\n",
    "* 1-conv-128-nodes-2-dense-1534801383\n",
    "* 2-conv-128-nodes-2-dense-1534801383\n",
    "* 3-conv-128-nodes-2-dense-1534801383\n",
    "\n",
    "<img src=\"https://pythonprogramming.net/static/images/machine-learning/optimizing-models.png\"> \n",
    "\n",
    "### Con esto podemos ver el top 10 de modelos\n",
    "* 3 conv, 64 nodes per layer, 0 dense\n",
    "* 3 conv, 128 nodes per layer, 0 dense\n",
    "* 3 conv, 32 nodes per layer, 0 dense\n",
    "* 3 conv, 32 nodes per layer, 2 dense\n",
    "* 3 conv, 32 nodes per layer, 1 dense\n",
    "* 2 conv, 32 nodes per layer, 0 dense\n",
    "* 2 conv, 64 nodes per layer, 0 dense\n",
    "* 3 conv, 128 nodes per layer, 1 dense\n",
    "* 2 conv, 128 nodes per layer, 0 dense\n",
    "* 2 conv, 32 nodes per layer, 1 dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por último para utilizar este modelo debemos utilizar el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "Dog\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = [\"Dog\", \"Cat\"]\n",
    "\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 100  # 50 in txt-based\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model(\"64x3-CNN.model\")\n",
    "\n",
    "prediction = model.predict([prepare('doggo.jpg')])\n",
    "print(prediction)  # will be a list in a list.\n",
    "print(CATEGORIES[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
